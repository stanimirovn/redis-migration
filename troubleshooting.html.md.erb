---
title: Troubleshooting Redis for VMware Tanzu Application Service
owner: London Services
---

<strong><%= modified_date %></strong>

This topic lists troubleshooting information for <%= vars.product_full %>.

<p class="note"><strong>Note</strong>:
  Some of the troubleshooting approaches in this topic suggest potentially destructive operations.
  VMware recommends that you back up both your <%= vars.ops_manager %> and deployments before attempting such operations.
  <br><br>
  For more information about backing up your setup and exporting your <%= vars.ops_manager %> installation,
  see <a href="https://docs.pivotal.io/pivotalcf/customizing/backup-restore/backup-pcf-bbr.html">Backing Up Deployments with BBR</a>
</p>


## <a id="debugging"></a> Useful Debugging Commands

Before debugging, gather the following information about your deployment:

* Current version of <%= vars.product_short %>, and, if upgrading, the previous version of <%= vars.product_short %>
* Current version of <%= vars.ops_manager %>, and, if upgrading, the previous version of <%= vars.ops_manager %>

### cf CLI Commands

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/redis/debugging-using-cf-cli' %>

### BOSH CLI Commands

See the table below for BOSH CLI commands commonly used while debugging:

<table>
  <col width="60%">
  <col width="40%">
  <tr>
    <th>Purpose</th>
    <th>Command</th>
  </tr>
  <tr>
    <td>View the targeted BOSH Director, version, and CPI</td>
    <td><code>bosh env</code></td>
  </tr>
  <tr>
    <td>View the deployments deployed through the targeted BOSH Director</td>
    <td><code>bosh deployments</code></td>
  </tr>
  <tr>
    <td>View the VMs for a given deployment</td>
    <td><code>bosh -d DEPLOYMENT vms</code></td>
  </tr>
  <tr>
    <td>SSH into a given deployment's VM</td>
    <td><code>bosh -d DEPLOYMENT ssh VM</code></td>
  </tr>
</table>

You can obtain general information after you SSH into a broker or service instance as follows:

* To see system logs, go to `/var/vcap/sys/log`.
* To check process health, run `sudo monit summary`.
* To obtain a list of all processes, run `ps aux`.
* To see disk usage, run `df -h`.
* To see memory usage, run `free -m`.

You can obtain information specific to the cf-redis broker as follows:

* For shared-VMs, the redis processes are co-located with the CF-Redis broker.
  You can check these VMs using `ps aux | grep redis-server`.
* Shared-VM data is stored in `/var/vcap/store/cf-redis-broker/redis-data`.


## <a id="redis-cli"></a> About the Redis CLI

The redis-cli is a command line tool used to access a Redis server.
You can use the redis-cli for create, read, update, and delete (CRUD) actions,
and to set configuration values.
For more information about the redis-cli, see [redis-cli, the Redis command
line interface](https://redis.io/topics/rediscli) in the Redis documentation.

To access the redis-cli, do the following:

1. Follow the instructions in [Access the Redis Service](./using.html#call)
to retrieve the password and port number for the service instance.

1. SSH into the service instance.

1. Connect to the Redis server and enter the redis-cli interactive mode by running:

    ```
    /var/vcap/packages/redis/bin/redis-cli -p PORT -a PASSWORD
    ```
    Where:
    <ul>
      <li><code>PORT</code> is the port number retrieved in step one.</li>
      <li><code>PASSWORD</code> is the password retrieved in step one.</li>
    </ul>
    For more information about the redis-cli interactive mode, see
    [Interactive Mode](https://redis.io/topics/rediscli#interactive-mode) in the
    Redis documentation.


## <a id="errors"></a> Troubleshoot Errors

Start here if you are responding to a specific error or error messages.

### <a id="x-product"></a> Common Services Errors

The following errors occur in multiple services:

+ [Failed Installation](#install-fail)
+ [Cannot Create or Delete Service Instances](#cannot-create-delete)
+ [Broker Request Timeouts](#timeouts)
+ [Instance Does Not Exist](#instance-not-exist)
+ [Cannot Bind to or Unbind from Service Instances](#cannot-bind)
+ [Cannot Connect to a Service Instance](#cannot-connect)
+ [Upgrade All Service Instances Errand Fails](#upgrade-all-fails)
+ [Missing Logs and Metrics](#missing-logs)

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-install-fail' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-cannot-create-delete' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-timeouts' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-instance-not-exist' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-other-errors' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-cannot-connect' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-upgrade-all-fails' %>

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-err-missing-logs' %>

### <a id="redis"></a> <%= vars.product_short %>-Specific Errors

The following troubleshooting errors are specific to <%= vars.product_short %>:

+ [AOF File Corrupted, Cannot Start Redis Instance](#corrupt-aof)
+ [Saving Error](#disk-size)
+ [Failed Backup](#backup-errors)
+ [Orphaned Instances: BOSH Director Cannot See Your Instances](#orphaned-bosh)
+ [Orphaned Instances: The Deployment Cannot See Your Instances](#orphaned-pcf)
+ [Failed to Set Credentials in Runtime CredHub](#credhub-error)
+ [Service Outage after Disabling TLS](#disabling-tls)

<a name="corrupt-aof"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    AOF File Corrupted, Cannot Start Redis Instance
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      One or more VMs might fail to start the Redis server during pre-start with the error message
      logged in syslog:
      <pre class="terminal">[ErrorLog-TimeStamp] # Bad file format reading the append only file: make a backup of your AOF file, then use ./redis-check-aof --fix `filename`</pre>
      For more information about remote syslog forwarding,
      see <a href="installing.html#syslog">Configure Syslog Forwarding</a>.
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      In cases of hard crashes, for example, due to power loss or VM termination without
      running drain scripts, your AOF file might become corrupted.
      The error log printed out by Redis provides a clear means of recovery.
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      <strong>Solution for Shared-VM instances:</strong><br><br>
      <ol>
        <li>SSH into your <code>cf-redis-broker</code> instance.</li>
        <li>
          Navigate to the directory where your AOF file is stored.
          This is usually
          <code>/var/vcap/store/cf-redis-broker/redis-data/SERVICE-INSTANCE-GUID/</code>, where
          <code>SERVICE-INSTANCE-GUID</code> is the GUID for the affected service instance.
        </li>
        <li>
          Run the following command:
          <pre class="terminal">/var/vcap/packages/redis/redis-check-aof appendonly.aof --fix</pre>
        </li>
        <li>
          To SSH out of the <code>cf-redis-broker</code> instance and restart, run the following command:
          <pre class="terminal">bosh restart INSTANCE-GROUP/INSTANCE-ID</pre>
        </li>
      </ol>

      <strong>Solution for On-Demand-VM instances:</strong><br><br>
      <ol>
        <li>SSH into your affected service instance.</li>
        <li>
          Navigate to the directory where your AOF file is stored.
          This is usually <code>/var/vcap/store/redis/</code>.
        </li>
        <li>
          Run:
          <pre class="terminal">/var/vcap/packages/redis/redis-check-aof appendonly.aof --fix</pre>
        </li>
        <li>
          SSH out of the service instance and restart it by running:
          <pre class="terminal">bosh restart INSTANCE-GROUP/INSTANCE-ID</pre>
        </li>
      </ol>
    </td>
  </tr>
</table>

<a name="disk-size"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Saving Error
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      One of the following error messages is logged in syslog:<br>
      <pre class="terminal">Background saving error</pre>
      <pre class="terminal">Failed opening the RDB file dump.rdb (in server root dir /var/vcap/store/redis) for saving: No space left on device</pre>
      For more information about remote syslog forwarding,
      see <a href="installing.html#syslog">Configure Syslog Forwarding</a>.
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      This might be logged when the configured disk size is too small,
      or if the Redis AOF uses all the disk space.
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      To prevent this error, do the following:<br><br>
      <ol>
        <li>
          Ensure the disk is configured to at least 2.5x the VM memory for the
          on-demand broker and 3.5x the VM memory for cf-redis-broker.
        </li>
        <li>
          Check if the AOF is using too much disk space by doing the following:
          <ol>
            <li>BOSH SSH into the affected service instance VM.</li>
            <li>
              List the size of each file by running:
              <pre class="terminal">cd /var/vcap/store/redis; ls -la</pre>
            </li>
          </ol>
        </li>
      </ol>
    </td>
  </tr>
</table>

<a name="backup-errors"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Failed Backup
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      The following error message is logged:<br>
      <pre class="terminal">Backup has failed. Redis must be running for a backup to run</pre>
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>This is logged if a backup is initiated against a Redis server that is down.</td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      Ensure that the Redis server being backed up is running.
      To do this, run <code>bosh restart</code> against the affected service instance VM.
    </td>
  </tr>
</table>

<a name="orphaned-bosh"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Orphaned Instances: BOSH Director Cannot See Your Instances
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      When you run <code>cf curl /v2/service_instances</code>,
      some service instances are visible that are not visible to the BOSH Director.
      These orphaned instances can create issues.
      For example, they might hold on to a static IP address, causing IP conflicts.
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      Orphaned instances can occur in the following situations:<br><br>
      <ul>
        <li>
          Both <%= vars.app_runtime_abbr %> and BOSH maintain state.
          Orphaned instances can occur if the <%= vars.app_runtime_abbr %> state is out of sync with BOSH.
          For example, the deployments or VMs have been de-provisioned by BOSH but
          the call to update the <%= vars.app_runtime_abbr %> state failed.
        </li>
        <li>
          If a call to de-provision a service instance was made directly to BOSH
          rather than through the cf CLI.
        </li>
      </ul>
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      You can solve this issue by doing one of the following:<br><br>
      <ul>
        <li>
          <strong>If this is the first occurrence:</strong> VMware recommends that you purge
          instances by running:
          <pre class="terminal">cf purge-service-instance SERVICE-INSTANCE</pre>.
        </li>
        <li>
          <strong>If this is a repeated occurrence:</strong> Contact
          <a href="https://support.pivotal.io/"> VMware Tanzu Support</a>
          for further help, and include the following:
          <ul>
            <li>A snippet of your <code>broker.log</code> around the time of the incident</li>
            <li>The deployment manifest of failed instances, hiding private information like passwords</li>
            <li>Any recent logs that you can recover from the failed service instance</li>
          </ul>
        </li>
      </ul>
    </td>
  </tr>
</table>

<a name="orphaned-pcf"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Orphaned Instances: The Deployment Cannot See Your Instances
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      The deployment cannot see your broker or service instances.
      These instances exist, but cannot receive communication.
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      If you run <code>cf purge-service-instances</code> while your service instance
      or broker still exists, your service instance becomes orphaned.
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      If the deployment lost the details of your instances,
      but BOSH still has the deployment details,
      you can solve this issue by backing up the data on your service instance and
      creating a new service. <br><br>
      To back up your data and create a new service instance:<br><br>
      <ol>
        <li>
          Retrieve your orphaned service instance GUID by running:
          <pre class="terminal">bosh -d MY-DEPLOYMENT run-errand orphan-deployments</pre>
          Where <code>MY-DEPLOYMENT</code> is the name of your deployment.
        </li>

        <li>
          SSH into your orphaned service instance by running:
          <pre class="terminal">bosh -e MY-ENV -d MY-DEPLOYMENT ssh VM-NAME/GUID</pre>
          Where:
          <ul>
            <li><code>MY-ENV</code> is the name of your environment.</li>
            <li><code>MY-DEPLOYMENT</code> is the name of your deployment.</li>
            <li><code>VM-NAME/GUID</code> is the name of your service instance
              and GUID that you obtained in step 1.</li>
          </ul>
        </li>

        <li>
          Create an new RDB file by running:
          <pre class="terminal">/var/vcap/jobs/redis-backups/bin/backup --snapshot</pre>
          This creates a new RDB file in <code>/var/vcap/store/redis-backup</code>.
        </li>

        <li>
          Push the RDB file to your backup location by running:
          <pre class="terminal">/var/vcap/jobs/service-backup/bin/manual-backup</pre>
          For information about backup locations,
          see <a href="./auto-backup.html">Configuring Automated Service Backups</a>.
        </li>

        <li>Create a new service instance with the same configuration of the database you backed up.</li>

        <li>
          Retrieve your new service instance GUID, by running:
          <pre class="terminal">bosh -e MY-ENV -d MY-DEPLOYMENT vms</pre>
          Where:
          <ul>
            <li><code>MY-ENV</code> is the name of your environment.</li>
            <li><code>MY-DEPLOYMENT</code> is the name of your deployment.</li>
          </ul>
        </li>

        <li>
          SSH into your new service instance by repeating step 2 above with the
          GUID that you retrieved in step 6.
        </li>

        <li>
          Create a new directory in new service instance by running:
          <pre class="terminal">mkdir /var/vcap/store/MY-BACKUPS</pre>
        </li>

        <li>
          Save the RDB file in <code>/var/vcap/store/MY-BACKUPS/</code> to transfer
          it to the new instance.
          Replace <code>MY-BACKUPS</code> with the name of your backups directory.
        </li>

        <li>
          Verify the RDB file has not been corrupted by running:
          <pre class="terminal">md5sum RDB-FILE</pre>
          Where <code>RDB-FILE</code> is the path to your RDB file.
        </li>

        <li>
          Restore your data by running:
          <pre class="terminal">sudo /var/vcap/jobs/redis-backups/bin/restore --sourceRDB RDB-FILE</pre>
          Where <code>RDB-FILE</code> is the path to your RDB file.
        </li>
      </ol>
    </td>
  </tr>
</table>

<a name="credhub-error"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Failed to Set Credentials in Runtime CredHub
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>
      If developers report errors such as:
      <pre class="terminal">error: failed to set credentials in credential store: The request includes an unrecognized parameter &#39;mode&#39;. Please update or remove this parameter and retry your request. error for user: There was a problem completing your request. Please contact your operations team providing the following information: service: p.redis, service-instance-guid: , broker-request-id: , operation: bind</pre>
    </td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      Your service instances might not be running the latest version of <%= vars.product_short %>.
      You might experience compatibility issues with CredHub if your service
      instances are running <%= vars.product_short %> v1.14.3 or earlier.
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      <ol>
        <li>
          Ensure you have the latest patch version of <%= vars.product_short %> installed.
          For more information about the latest patch, see the
          <a href="./release.html"><%= vars.product_full %> Release Notes</a>.
        </li>
        <li>
          Run the <code>upgrade-all-service-instances</code> errand to ensure all service
          instances are running the latest service offering.
          For how to run the errand, see <a href="#upgrade-all">Upgrade All Service Instances</a>.
          <p class="note">
            <strong>Note:</strong> Running this errand causes a short period of downtime.
          </p>
        </li>
      </ol>
    </td>
  </tr>
</table>

<a name="disabling-tls"></a>
<table class="nice">
  <style>
    main table {
      table-layout: fixed;
    }
  </style>
  <col width="20%">
  <col width="80%">
  <tr>
  <th colspan="2" style="text-align: left;">
    <br>
    Service Outage after Disabling TLS
    <br><br>
  </th>
  </tr>
  <tr>
    <th>Symptom</th>
    <td>After disabling TLS, apps that require on-demand Redis service instances become unresponsive.</td>
  </tr>
  <tr>
    <th>Cause</th>
    <td>
      When TLS is first enabled, all on-demand service instances are re-created with two ports.
      Every new or re-created app receives the new credentials.
      Spring and Steeltoe apps are configured for enabled TLS by default, but other
      languages and frameworks require further configuration.
      <br><br>
      When TLS is disabled, the TLS port is removed from all on-demand instances.
      This prevents the apps from connecting to the instance.
    </td>
  </tr>
  <tr>
    <th style="vertical-align: top; padding-top: 1em;">Solution</th>
    <td>
      <p>
        First, consider enabling TLS.
        The compliance body that oversees your apps might require TLS to be enabled.
        Also, switching between enabled and disabled TLS incurs downtime.
      </p>
      <p>To enable TLS, follow these steps:</p>
      <ol>
        <li>In your <%= vars.ops_manager %> home page, select the <strong>Redis</strong> tile.</li>
        <li>Navigate to <strong>On-Demand Service Settings.</strong></li>
        <li>On the <strong>Enable TLS</strong> section, ensure it is set to <strong>Optional</strong>.</li>
        <li>Click <strong>Save</strong>.</li>
        <li>
          Navigate back to the <%= vars.ops_manager %> home page and click
          <strong>Review Pending Changes</strong>.
        </li>
        <li>
          Ensure the Recreate All On-Demand Service Instances errand is enabled under the
          Redis section and then click <strong>Apply Changes</strong>.
        </li>
      </ol>
      <p>To continue with TLS disabled, follow these steps:</p>
      <ol>
        <li>
          Unbind, bind, and re-stage every app that was affected by disabling TLS.
          For more information, see <a href="./appdevs.html">Introduction for App Developers</a>.
          This makes Spring and Steeltoe apps default to non-TLS configuration.
        </li>
        <li>Manually configure any other relevant languages and frameworks to work with TLS disabled.</li>
      </ol>
    </td>
  </tr>
</table>

## <a id="components"></a> Troubleshoot Components

This section provides guidance on checking for, and fixing, issues in cf-redis and on-demand service components.

### <a id="bosh"></a> BOSH Problems

#### <a id="large-queue"></a> Large BOSH Queue

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-large-queue' %>

### <a id="bosh-config"></a> Configuration

#### <a id="bosh-instance-fail"></a> Service Instances in Failing State

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-bosh-instance-fail' %>

### <a id="auth"></a> Authentication

#### <a id="uaa-change"></a> UAA Changes

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-uaa-change' %>

### <a id="network"></a> Networking

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-network' %>

#### <a id="broker-to-instances"></a> Validate Service Broker Connectivity to Service Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-broker-to-instances' %>

#### <a id="app-to-instances"></a> Validate App Access to a Service Instance

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-app-to-instances' %>

### <a id="quotas"></a> Quotas

#### <a id="plan-quotas"></a> Plan Quota Issues

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-plan-quotas' %>

#### <a id="global-quotas"></a> Global Quota Issues

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-global-quotas' %>

### <a id="failing-jobs"></a> Failing Jobs and Unhealthy Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-comp-failing-jobs' %>

## <a id="techniques"></a> Techniques for Troubleshooting

This section contains instructions on:

*   Interacting with the on-demand service broker
*   Interacting with on-demand service instance BOSH deployments
*   Performing general maintenance and housekeeping tasks

### <a id="parse-error"></a> Parse a Cloud Foundry (CF) Error Message

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-parse-error' %>

### <a id="bosh-cf-access"></a>Access Broker and Instance Logs and VMs

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-bosh-cf-access' %>

#### <a id="access-broker"></a> Access Broker Logs and VMs

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-access-broker' %>

#### <a id="access-instance"></a> Access Service Instance Logs and VMs

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-access-instance' %>

### <a id="broker-errands"></a> Run Service Broker Errands to Manage Brokers and Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-broker-errands' %>

#### <a id="register-broker"></a> Register Broker

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-register-broker' %>

#### <a id="deregister-broker"></a> Deregister Broker

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-deregister-broker' %>

#### <a id="upgrade-all"></a> Upgrade All Service Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-upgrade-all' %>

#### <a id="delete-all"></a> Delete All Service Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-delete-all' %>

#### <a id="detect-orphans"></a> Detect Orphaned Service Instances

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-detect-orphans' %>

### <a id="instance-creds"></a> Get Admin Credentials for a Service Instance

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-instance-creds' %>

### <a id="reinstall"></a> Reinstall a Tile

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-reinstall' %>

### <a id="view-resources"></a> View Resource Saturation and Scaling

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-view-resources' %>

### <a id="id-instance-owner"></a> Identify Apps using a Service Instance

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-id-instance-owner' %>

### <a id="monitor-quota"></a> Monitor the Quota Saturation and Service Instance Count

<%# The below partial is in https://github.com/pivotal-cf/docs-partials %>

<%= partial vars.path_to_partials + '/services-tshoot/tshoot-tech-monitor-quota' %>


## <a id="Knowledge"></a> VMware Tanzu Support Articles

The following are <a href="https://community.pivotal.io/s/">VMware Tanzu Support</a> articles about <%= vars.product_short %>:
<ul>
  <li><a href="https://community.pivotal.io/s/article/Creating-an-Empty-Services-Network-when-using-on-demand-Service-Tiles-for-Non-On-Demand-Usage-Only">Creating an Empty Services Network when using on-demand Service Tiles for Non-On-Demand Usage Only </a></li>
  <li><a href="https://community.pivotal.io/s/article/Pivotal-Cloud-Foundry-Redis-full-disk-scaling-issue">Full disk scaling issue</a></li>
  <li><a href="https://community.pivotal.io/s/article/Pivotal-Cloud-Foundry-Redis-tile-upgrade-issue">Tile upgrade issue</a></li>
  <li><a href="https://community.pivotal.io/s/article/Pivotal-Cloud-Foundry-Redis-Deploy-Fails-to-Complete">Deploy Fails to Complete</a></li>
  <li><a href="https://community.pivotal.io/s/article/Pivotal-Cloud-Foundry-Redis-Instance-Alive-after-Successful-De-Provisioning">Instance Alive after Successful De-Provisioning</a></li>
  <li><a href="https://community.pivotal.io/s/article/PCF-Redis-Dedicated-Instance-Fails-to-Persist-to-Disk">Dedicated Instance Fails to Persist to Disk</a></li>
  <li><a href="https://community.pivotal.io/s/article/67-Redis-error-when-saving-changes-after-a-back-up-to-AWS-S3-Error-Access-Denied-for-bucket-pcf-redos-backup-sgp-intra-test">Redis error when saving changes after a back to AWS S3: Error: Access Denied for bucket 'pcf-redos-backup-sgp-intra-test'</a></li>
  <li><a href="https://community.pivotal.io/s/article/48-For-service-settings-on-Redis-Tile-the-VM-options-checkbox-needs-to-be-checked-for-GCP-Environment">For service settings on Redis Tile, the VM options checkbox needs to be checked for GCP Environment</a></li>
  <li><a href="https://community.pivotal.io/s/article/Removing-dedicated-vm-Service-Instances-from-the-CF-when-deleted-from-BOSH"> Removing dedicated-vm Service Instances on CF when already deleted from BOSH</a></li>
  <li><a href="https://community.pivotal.io/s/article/Migrating-from-dedicated-vm-service-plans-to-on-demand-service-plans">Migrating from dedicated-vm service plans to on-demand service plans</a></li>
</ul>
